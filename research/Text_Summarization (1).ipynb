{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jwv4bHLYjc0u"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hn-Pbfsqi16q"},"outputs":[],"source":["!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPut8GjRl7gt"},"outputs":[],"source":["!pip install --upgrade accelerate\n","!pip uninstall -y transformers accelerate\n","!pip install transformers accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBVLYqfQp5tm"},"outputs":[],"source":["!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bM3ORFYNjKRH"},"outputs":[],"source":["from datasets import load_dataset, load_from_disk\n","import matplotlib.pyplot as plt\n","from datasets import load_dataset\n","import pandas as pd\n","from datasets import load_dataset\n","from evaluate import load # Load load_metric from evaluate instead of datasets\n","\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from tqdm import tqdm\n","import torch\n","\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYUxA3GkpaaU"},"outputs":[],"source":["from datasets import load_dataset, load_from_disk\n","import matplotlib.pyplot as plt\n","from datasets import load_dataset\n","import pandas as pd\n","from datasets import load_dataset\n","from evaluate import load # Load load_metric from evaluate instead of datasets\n","\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from tqdm import tqdm\n","import torch\n","\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2Y1Agn7pj7P"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxvLZ4Zkjf82"},"outputs":[],"source":["model_ckpt = \"google/pegasus-cnn_dailymail\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","\n","model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1734087345226,"user":{"displayName":"Moksha Dilshan","userId":"08218388806443248424"},"user_tz":-330},"id":"8vg_V-Kpjmo1","outputId":"e201186c-8d3e-49f3-8e30-9efb940d8a61"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-12-13 10:55:42--  https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/summarizer-data.zip [following]\n","--2024-12-13 10:55:43--  https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/summarizer-data.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7903594 (7.5M) [application/zip]\n","Saving to: ‘summarizer-data.zip’\n","\n","summarizer-data.zip 100%[===================>]   7.54M  --.-KB/s    in 0.08s   \n","\n","2024-12-13 10:55:44 (96.4 MB/s) - ‘summarizer-data.zip’ saved [7903594/7903594]\n","\n","Archive:  summarizer-data.zip\n","  inflating: samsum-test.csv         \n","  inflating: samsum-train.csv        \n","  inflating: samsum-validation.csv   \n","   creating: samsum_dataset/\n"," extracting: samsum_dataset/dataset_dict.json  \n","   creating: samsum_dataset/test/\n","  inflating: samsum_dataset/test/data-00000-of-00001.arrow  \n","  inflating: samsum_dataset/test/dataset_info.json  \n","  inflating: samsum_dataset/test/state.json  \n","   creating: samsum_dataset/train/\n","  inflating: samsum_dataset/train/data-00000-of-00001.arrow  \n","  inflating: samsum_dataset/train/dataset_info.json  \n","  inflating: samsum_dataset/train/state.json  \n","   creating: samsum_dataset/validation/\n","  inflating: samsum_dataset/validation/data-00000-of-00001.arrow  \n","  inflating: samsum_dataset/validation/dataset_info.json  \n","  inflating: samsum_dataset/validation/state.json  \n"]}],"source":["#dowload & unzip data\n","\n","!wget https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip\n","!unzip summarizer-data.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7pO1I7rPj-nc"},"outputs":[],"source":["dataset_samsum = load_from_disk('samsum_dataset')\n","dataset_samsum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDOFV1QAkVM1"},"outputs":[],"source":["split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n","\n","print(f\"Split lengths: {split_lengths}\")\n","print(f\"Features: {dataset_samsum['train'].column_names}\")\n","print(\"\\nDialogue:\")\n","\n","print(dataset_samsum[\"test\"][1][\"dialogue\"])\n","\n","print(\"\\nSummary:\")\n","\n","print(dataset_samsum[\"test\"][1][\"summary\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjqrjnHOkibG"},"outputs":[],"source":["def convert_examples_to_features(example_batch):\n","    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n","\n","    with tokenizer.as_target_tokenizer():\n","        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n","\n","    return {\n","        'input_ids' : input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovCPjEQOks2d"},"outputs":[],"source":["dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tC1AbgA-kvCm"},"outputs":[],"source":["dataset_samsum_pt[\"train\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWZboBc5k2Ul"},"outputs":[],"source":["# Training\n","\n","from transformers import DataCollatorForSeq2Seq\n","\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETrjK2FZlDY2"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","trainer_args = TrainingArguments(\n","    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n","    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","    weight_decay=0.01, logging_steps=10,\n","    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n","    gradient_accumulation_steps=16\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eHrye9salGGW"},"outputs":[],"source":["\n","trainer = Trainer(model=model_pegasus, args=trainer_args,\n","                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n","                  train_dataset=dataset_samsum_pt[\"test\"],\n","                  eval_dataset=dataset_samsum_pt[\"validation\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":327},"id":"DwpPL9fMl1xU","outputId":"ce3dc99f-65fb-46b2-e5f6-701a480f72f6"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmokshadil\u001b[0m (\u001b[33mmokshadil-mdw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20241213_140219-gfwkwvot</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/mokshadil-mdw/huggingface/runs/gfwkwvot' target=\"_blank\">pegasus-samsum</a></strong> to <a href='https://wandb.ai/mokshadil-mdw/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/mokshadil-mdw/huggingface' target=\"_blank\">https://wandb.ai/mokshadil-mdw/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/mokshadil-mdw/huggingface/runs/gfwkwvot' target=\"_blank\">https://wandb.ai/mokshadil-mdw/huggingface/runs/gfwkwvot</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [51/51 03:30, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n"]},{"data":{"text/plain":["TrainOutput(global_step=51, training_loss=3.004438227298213, metrics={'train_runtime': 218.8836, 'train_samples_per_second': 3.742, 'train_steps_per_second': 0.233, 'total_flos': 313450454089728.0, 'train_loss': 3.004438227298213, 'epoch': 0.9963369963369964})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["f9367ce1d1de4899be818f6ebf774212"]},"id":"u4vC-cqytjoV","outputId":"12df6f7b-1357-4047-f9ca-432a95d9040b"},"outputs":[{"data":{"text/html":["Finishing last run (ID:gfwkwvot) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9367ce1d1de4899be818f6ebf774212","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.021 MB of 0.021 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <style>\n","        .wandb-row {\n","            display: flex;\n","            flex-direction: row;\n","            flex-wrap: wrap;\n","            justify-content: flex-start;\n","            width: 100%;\n","        }\n","        .wandb-col {\n","            display: flex;\n","            flex-direction: column;\n","            flex-basis: 100%;\n","            flex: 1;\n","            padding: 10px;\n","        }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▃▄▆██</td></tr><tr><td>train/global_step</td><td>▁▃▄▆██</td></tr><tr><td>train/grad_norm</td><td>▂▅█▁▄</td></tr><tr><td>train/learning_rate</td><td>▁▃▅▆█</td></tr><tr><td>train/loss</td><td>▇█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>313450454089728.0</td></tr><tr><td>train/epoch</td><td>0.99634</td></tr><tr><td>train/global_step</td><td>51</td></tr><tr><td>train/grad_norm</td><td>232.95003</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>2.8829</td></tr><tr><td>train_loss</td><td>3.00444</td></tr><tr><td>train_runtime</td><td>218.8836</td></tr><tr><td>train_samples_per_second</td><td>3.742</td></tr><tr><td>train_steps_per_second</td><td>0.233</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">pegasus-samsum</strong> at: <a href='https://wandb.ai/mokshadil-mdw/huggingface/runs/gfwkwvot' target=\"_blank\">https://wandb.ai/mokshadil-mdw/huggingface/runs/gfwkwvot</a><br/> View project at: <a href='https://wandb.ai/mokshadil-mdw/huggingface' target=\"_blank\">https://wandb.ai/mokshadil-mdw/huggingface</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241213_140219-gfwkwvot/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:gfwkwvot). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20241213_140556-6rofncnz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/mokshadil-mdw/pegasus-samsum-summarization/runs/6rofncnz' target=\"_blank\">dry-yogurt-6</a></strong> to <a href='https://wandb.ai/mokshadil-mdw/pegasus-samsum-summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/mokshadil-mdw/pegasus-samsum-summarization' target=\"_blank\">https://wandb.ai/mokshadil-mdw/pegasus-samsum-summarization</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/mokshadil-mdw/pegasus-samsum-summarization/runs/6rofncnz' target=\"_blank\">https://wandb.ai/mokshadil-mdw/pegasus-samsum-summarization/runs/6rofncnz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [51/51 04:05, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=51, training_loss=2.7390929250156177, metrics={'train_runtime': 248.5472, 'train_samples_per_second': 3.295, 'train_steps_per_second': 0.205, 'total_flos': 313450454089728.0, 'train_loss': 2.7390929250156177, 'epoch': 0.9963369963369964})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","\n","# ... your existing code ...\n","\n","# Before trainer.train()\n","wandb.init(project=\"pegasus-samsum-summarization\") # Choose a project name\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pVP4cS-7mLeH"},"outputs":[],"source":["# Evaluation\n","\n","def generate_batch_sized_chunks(list_of_elements, batch_size):\n","    \"\"\"split the dataset into smaller batches that we can process simultaneously\n","    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n","    for i in range(0, len(list_of_elements), batch_size):\n","        yield list_of_elements[i : i + batch_size]\n","\n","\n","\n","def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n","                               batch_size=16, device=device,\n","                               column_text=\"article\",\n","                               column_summary=\"highlights\"):\n","    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n","    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n","\n","    for article_batch, target_batch in tqdm(\n","        zip(article_batches, target_batches), total=len(article_batches)):\n","\n","        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n","                        padding=\"max_length\", return_tensors=\"pt\")\n","\n","        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n","                         attention_mask=inputs[\"attention_mask\"].to(device),\n","                         length_penalty=0.8, num_beams=8, max_length=128)\n","        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n","\n","        # Finally, we decode the generated texts,\n","        # replace the  token, and add the decoded texts with the references to the metric.\n","        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n","                                clean_up_tokenization_spaces=True)\n","               for s in summaries]\n","\n","        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n","\n","\n","        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n","\n","    #  Finally compute and return the ROUGE scores.\n","    score = metric.compute()\n","    return score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mxHIt7sGmYrN"},"outputs":[],"source":["rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","rouge_metric = load_metric('rouge')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRiJW_JbmYom"},"outputs":[],"source":["score = calculate_metric_on_test_ds(\n","    dataset_samsum['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",")\n","\n","rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = [f'pegasus'] )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SJyDIKWZmoUj"},"outputs":[],"source":["## Save model\n","model_pegasus.save_pretrained(\"pegasus-samsum-model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"w26e-0yemoRt"},"outputs":[],"source":["## Save tokenizer\n","tokenizer.save_pretrained(\"tokenizer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHeUCFaJmoPV"},"outputs":[],"source":["#Load\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/tokenizer\")"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"l4ekcN9Sm1Lk","executionInfo":{"status":"error","timestamp":1734113128037,"user_tz":-330,"elapsed":611,"user":{"displayName":"Moksha Dilshan","userId":"08218388806443248424"}},"outputId":"0ca6d376-83a5-444a-a785-fb3c74c81045","colab":{"base_uri":"https://localhost:8080/","height":211}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dataset_samsum' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-57dd539c7c35>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msample_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_samsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dialogue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_samsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset_samsum' is not defined"]}],"source":["#Prediction\n","\n","gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n","\n","\n","\n","sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n","\n","reference = dataset_samsum[\"test\"][0][\"summary\"]\n","\n","pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n","\n","##\n","print(\"Dialogue:\")\n","print(sample_text)\n","\n","\n","print(\"\\nReference Summary:\")\n","print(reference)\n","\n","\n","print(\"\\nModel Summary:\")\n","print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}